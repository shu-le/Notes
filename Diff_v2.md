## Text-to-image

[Aligning Text-to-Image Diffusion Models with Reward Backpropagation](https://arxiv.org/abs/2310.03739) 5 Oct 23

[FreeU: Free Lunch in Diffusion U-Net](https://arxiv.org/abs/2309.11497) 20 Seq 23

[Emu: Enhancing Image Generation Models Using Photogenic Needles in a Haystack](https://huggingface.co/papers/2309.15807)



## Control diffusion

[Zero-shot spatial layout conditioning for text-to-image diffusion models](https://arxiv.org/abs/2306.13754)

[Generate Anything Anywhere in Any Scene](https://arxiv.org/abs/2306.17154)

[ConceptLab: Creative Generation using Diffusion Prior Constraints](https://huggingface.co/papers/2308.02669)

[IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models](https://huggingface.co/papers/2308.06721)

[DreamStyler: Paint by Style Inversion with Text-to-Image Diffusion Models](https://huggingface.co/papers/2309.06933)



## Video diffusion

[AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning](https://arxiv.org/abs/2307.04725)

[TokenFlow: Consistent Diffusion Features for Consistent Video Editing](https://huggingface.co/papers/2307.10373)

[Multiscale Video Pretraining for Long-Term Activity Forecasting](https://huggingface.co/papers/2307.12854)

[Dual-Stream Diffusion Net for Text-to-Video Generation](https://huggingface.co/papers/2308.08316)

[DragNUWA: Fine-grained Control in Video Generation by Integrating Text, Image, and Trajectory](https://huggingface.co/papers/2308.08089)

[VideoGen: A Reference-Guided Latent Diffusion Approach for High Definition Text-to-Video Generation](https://huggingface.co/papers/2309.00398)

[MagicProp: Diffusion-based Video Editing via Motion-aware Appearance Propagation](https://huggingface.co/papers/2309.00908)

[Reuse and Diffuse: Iterative Denoising for Text-to-Video Generation](https://huggingface.co/papers/2309.03549)

[LAVIE: High-Quality Video Generation with Cascaded Latent Diffusion Models](https://huggingface.co/papers/2309.15103)

[VideoDirectorGPT: Consistent Multi-scene Video Generation via LLM-Guided Planning](https://huggingface.co/papers/2309.15091)





[Diffusion Generative Inverse Design](https://huggingface.co/papers/2309.02040)

[Generative Image Dynamics](https://huggingface.co/papers/2309.07906)
