Other:

​	[3D-VLA: A 3D Vision-Language-Action Generative World Model](https://arxiv.org/abs/2403.09631)

​	Long-CLIP: Unlocking the Long-Text Capability of CLIP

​	[What the DAAM: Interpreting Stable Diffusion Using Cross Attention](https://arxiv.org/abs/2210.04885) 解释sd

​	[Distributional Preference Alignment of LLMs via Optimal Transport](https://arxiv.org/abs/2406.05882)

​	[MOT: A Mixture of Actors Reinforcement Learning Method by Optimal Transport for Algorithmic Trading](https://arxiv.org/abs/2407.01577) 最优传输

​	[Multi-objective Reinforcement learning from AI Feedback](https://arxiv.org/abs/2406.07295)

​	[Joint Demonstration and Preference Learning Improves Policy Alignment with Human Feedback](https://arxiv.org/abs/2406.06874)

​	[Direct Language Model Alignment from Online AI Feedback](https://arxiv.org/abs/2402.04792) 各种算法Online差别不大但都比Offline好

​	[DPO Meets PPO: Reinforced Token Optimization for RLHF](https://arxiv.org/pdf/2404.18922)

​	[Interpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts](https://arxiv.org/abs/2406.12845)

​	[Understanding the performance gap between online and offline alignment algorithms](https://arxiv.org/abs/2405.08448)

​	[Beyond One-Preference-Fits-All Alignment: **Multi-Objective Direct Preference Optimization**](https://arxiv.org/abs/2310.03708)

​	[Iterative Nash Policy Optimization: Aligning LLMs with General Preferences via No-Regret Learning](https://arxiv.org/abs/2407.00617)

​	Beyond Thumbs Up/Down: Untangling Challenges of Fine-Grained Feedback for Text-to-Image Generation 【Multi reward】



​	[Boosting Consistency in Story Visualization with Rich-Contextual Conditional Diffusion Models](https://arxiv.org/abs/2407.02482) **[可能用到]**

​	[Rewarded soups: towards Pareto-optimal alignment by interpolating weights fine-tuned on diverse rewards](https://arxiv.org/abs/2306.04488)

​	[Stylus: Automatic Adapter Selection for Diffusion Models](https://arxiv.org/pdf/2404.18928)



dataset:

​	[MantisScore: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation](https://arxiv.org/abs/2406.15252)



ICML24: 

​	[Dense Reward for Free in Reinforcement Learning from Human Feedback](https://arxiv.org/abs/2402.00782)

​	[Generative Active Learning for Long-tailed Instance Segmentation](https://arxiv.org/abs/2406.02435) 

​	Visual-Language Models as Fuzzy Rewards for Reinforcement Learning

​	[Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint](https://arxiv.org/abs/2312.11456)

​	[Token-level Direct Preference Optimization](https://arxiv.org/abs/2404.11999)

​	[Reward Model Learning vs. Direct Policy Optimization: A Comparative Analysis of Learning from Human Preferences](https://arxiv.org/abs/2403.01857)

​	[A Dense Reward View on Aligning Text-to-Image Diffusion with Preference](https://arxiv.org/abs/2402.08265)

​	[On Discrete Prompt Optimization for Diffusion Models](https://arxiv.org/abs/2407.01606)

​	[Active Preference Learning for Large Language Models](https://arxiv.org/pdf/2402.08114)

​	[Rewards-in-Context: Multi-objective Alignment of Foundation Models with Dynamic Preference Adjustment](https://arxiv.org/pdf/2402.10207)

​	[Linear Alignment: A Closed-form Solution for Aligning Human Preferences without Tuning and Feedback](https://arxiv.org/pdf/2401.11458)

​	MaxMin-RLHF: Alignment with Diverse Human Preferences

​	[Feedback Efficient Online Fine-Tuning of Diffusion Models](https://arxiv.org/abs/2402.16359)



video:

[Momentor: Advancing Video Large Language Model with Fine-Grained Temporal Reasoning](https://arxiv.org/abs/2402.11435)

[4Diffusion: Multi-view Video Diffusion Model for 4D Generation](https://arxiv.org/abs/2405.20674)

[Diffusion4D: Fast Spatial-temporal Consistent 4D Generation via Video Diffusion Models](https://arxiv.org/abs/2405.16645)



NeurIPS

​	RLHF:

​	[Information Theoretic Text-to-Image Alignment](https://arxiv.org/abs/2405.20759)

​	[Boost Your Own Human Image Generation Model via Direct Preference Optimization with AI Feedback](https://arxiv.org/abs/2405.20216)

​	[Scaling Laws for Reward Model Overoptimization in Direct Alignment Algorithms](https://arxiv.org/abs/2406.02900)

​	[Step-aware Preference Optimization: Aligning Preference with Denoising Performance at Each Step](https://arxiv.org/abs/2406.04314)

​	[Tuning-Free Alignment of Diffusion Models with Direct Noise Optimization](https://arxiv.org/abs/2405.18881)

​	[ReNO: Enhancing One-step Text-to-Image Models through Reward-based Noise Optimization](https://arxiv.org/abs/2406.04312)

​	[Margin-aware Preference Optimization for Aligning Diffusion Models without Reference](https://arxiv.org/abs/2406.06424) ORPO

​	[Diffusion-RPO: Aligning Diffusion Models through Relative Preference Optimization](https://arxiv.org/abs/2406.06382)

​		Two insights: preference learning and conditional transport framework, a new downstream task with datasets specifically designed for image preference learning

​	[Online DPO: Online Direct Preference Optimization with Fast-Slow Chasing](https://arxiv.org/abs/2406.05534)

​	[3D-Properties: Identifying Challenges in DPO and Charting a Path Forward](https://arxiv.org/abs/2406.07327)

​	[OPTune: Efficient Online Preference Tuning](https://arxiv.org/abs/2406.07657)

​	[Aligning Vision Models with Human Aesthetics in Retrieval: Benchmarks and Algorithms](https://arxiv.org/abs/2406.09397)

​	[Online Bandit Learning with Offline Preference Data](https://arxiv.org/abs/2406.09574)

​	[Bootstrapping Language Models with DPO Implicit Rewards](https://arxiv.org/abs/2406.09760)

​	[SafeSora: Towards Safety Alignment of Text2Video Generation via a Human Preference Dataset](https://arxiv.org/abs/2406.14477)

​	[Aligning Diffusion Models with Noise-Conditioned Perception](https://arxiv.org/abs/2406.17636)

​	[Pareto-Optimal Learning from Preferences with Hidden Context](https://arxiv.org/abs/2406.15599)

​	[Maximum Entropy Inverse Reinforcement Learning of Diffusion Models with Energy-Based Models](https://arxiv.org/abs/2407.00626)

​	[Understanding Alignment in Multimodal LLMs: A Comprehensive Study](https://arxiv.org/abs/2407.02477)

​	[Aligning Target-Aware Molecule Diffusion Models with Exact Energy Optimization](https://arxiv.org/abs/2407.01648) 写作参考

​	[Q-Adapter: Training Your LLM Adapter as a Residual Q-Function](https://arxiv.org/pdf/2407.03856)

​	[Video Diffusion Alignment via Reward Gradients](https://arxiv.org/abs/2407.08737)

​	[β-DPO: Direct Preference Optimization with Dynamic β](https://arxiv.org/pdf/2407.08639)

​	[Self-Consuming Generative Models with Curated Data Provably Optimize Human Preferences](https://arxiv.org/pdf/2407.09499)

​	[Subject-driven Text-to-Image Generation via Preference-based Reinforcement Learning](https://arxiv.org/abs/2407.12164)

​	[Rule Based Rewards for Language Model Safety](https://cdn.openai.com/rule-based-rewards-for-language-model-safety.pdf)



​	Video:

​	[Searching Priors Makes Text-to-Video Synthesis Better](https://arxiv.org/abs/2406.03215)

​	[ShareGPT4Video: Improving Video Understanding and Generation with Better Captions](https://arxiv.org/abs/2406.04325)

​	[VIDEOPHY: Evaluating Physical Commonsense for Video Generation](https://arxiv.org/abs/2406.03520)

​	[Vript: A Video Is Worth Thousands of Words](https://arxiv.org/abs/2406.06040)

​	[**Splatter a Video: Video Gaussian Representation for Versatile Processing**](https://arxiv.org/abs/2406.13870)(或许可以用来reward)

​	[MotionBooth: Motion-Aware Customized Text-to-Video Generation](https://arxiv.org/abs/2406.17758)

​	[Video-Infinity: Distributed Long Video Generation](https://arxiv.org/abs/2406.16260)

​	[What Matters in Detecting AI-Generated Videos like Sora?](https://arxiv.org/abs/2406.19568)

​	[SVG: 3D Stereoscopic Video Generation via Denoising Frame Matrix](https://arxiv.org/abs/2407.00367)

​	[Maximum Entropy Inverse Reinforcement Learning of Diffusion Models with Energy-Based Models](https://arxiv.org/abs/2407.00626)

​	[Lumina-Next: Making Lumina-T2X Stronger and Faster with Next-DiT](https://arxiv.org/pdf/2406.18583)

​	[OpenVid-1M: A Large-Scale High-Quality Dataset for Text-to-video Generation](https://arxiv.org/abs/2407.02371)

​	[InVi: Object Insertion In Videos Using Off-the-Shelf Diffusion Models](https://arxiv.org/pdf/2407.10958)

​	[VD3D: Taming Large Video Diffusion Transformers for 3D Camera Control](https://arxiv.org/pdf/2407.12781)

​	[VideoTetris: Towards Compositional Text-to-Video Generation](https://arxiv.org/pdf/2406.04277)

​	[Cinemo: Consistent and Controllable Image Animation with Motion Diffusion Models ](https://arxiv.org/pdf/2407.15642) learn motion residuals



​	Image: 

​	[Text-to-Image Rectified Flow as Plug-and-Play Priors](https://arxiv.org/abs/2406.03293)

​	[Adapter-X: A Novel General Parameter-Efficient Fine-Tuning Framework for Vision](https://arxiv.org/abs/2406.03051) (Mixture of Adapters)

​	[Understanding the Impact of Negative Prompts: When and How Do They Take Effect?](https://arxiv.org/abs/2406.02965)

​	[Guiding a Diffusion Model with a Bad Version of Itself](https://arxiv.org/abs/2406.02507)

​	[An Image is Worth 32 Tokens for Reconstruction and Generation](https://arxiv.org/abs/2406.07550)

​	[Ctrl-X: Controlling Structure and Appearance for Text-To-Image Generation Without Guidance](https://arxiv.org/abs/2406.07540)

​	[Interpreting the Weight Space of Customized Diffusion Models](https://arxiv.org/abs/2406.09413)

​	[Magic Insert: Style-Aware Drag-and-Drop](https://arxiv.org/abs/2407.02489)

​	[Long and Short Guidance in Score identity Distillation for One-Step Text-to-Image Generation](https://arxiv.org/pdf/2406.01561)

​	[**Scaling Diffusion Transformers to 16 Billion Parameters**](https://arxiv.org/pdf/2407.11633)

​	[Beta Sampling is All You Need: Efficient Image Generation Strategy for Diffusion Models using Stepwise Spectral Analysis](https://arxiv.org/pdf/2407.12173) 频率分析



​	Evaluate and Benchmark or Dataset:

​	[A-Bench: Are LMMs Masters at Evaluating AI-generated Images?](https://arxiv.org/abs/2406.03070) Benchmark

​	[GAIA: Rethinking Action Quality Assessment for AI-Generated Videos](https://arxiv.org/abs/2406.06087)

​	[Commonsense-T2I Challenge: Can Text-to-Image Generation Models Understand Commonsense?](https://arxiv.org/abs/2406.07546)

​	[Rethinking Human Evaluation Protocol for Text-to-Video Models: Enhancing Reliability,Reproducibility, and Practicality](https://arxiv.org/abs/2406.08845)

​	[TC-Bench: Benchmarking Temporal Compositionality in Text-to-Video and Image-to-Video Generation](https://arxiv.org/abs/2406.08656)

​	[VideoGUI: A Benchmark for GUI Automation from Instructional Videos](https://arxiv.org/abs/2406.10227)

​	[GenAI-Bench: Evaluating and Improving Compositional Text-to-Visual Generation](https://arxiv.org/abs/2406.13743)

​	[EVALALIGN: Supervised Fine-Tuning Multimodal LLMs with Human-Aligned Data for Evaluating Text-to-Image Models](https://arxiv.org/abs/2406.16562)

​	[Evaluation of Text-to-Video Generation Models: A Dynamics Perspective](https://arxiv.org/abs/2407.01094)

​	[Rethinking LLM-based Preference Evaluation](https://arxiv.org/abs/2407.01085)

​	**[MJ-BENCH: Is Your Multimodal Reward Model Really a Good Judge for Text-to-Image Generation?](https://arxiv.org/pdf/2407.04842)**  multi-dimensional preference dataset

​	[T2V-CompBench: A Comprehensive Benchmark for Compositional Text-to-video Generation](https://arxiv.org/pdf/2407.14505)



​	3D:

​	[Physics3D: Learning Physical Properties of 3D Gaussians via Video Diffusion](https://arxiv.org/abs/2406.04338)

​	[Flash3D: Feed-Forward Generalisable 3D Scene Reconstruction from a Single Image](https://arxiv.org/abs/2406.04343)

​	[L4GM: Large 4D Gaussian Reconstruction Model](https://arxiv.org/abs/2406.10324)

​	[A3D: Does Diffusion Dream about 3D Alignment?](https://arxiv.org/abs/2406.15020v1) 可能有用

​	[Director3D: Real-world Camera Trajectory and 3D Scene Generation from Text](https://arxiv.org/abs/2406.17601)

​	[ScaleDreamer: Scalable Text-to-3D Synthesis with Asynchronous Score Distillation](https://arxiv.org/abs/2407.02040)

​	[Controlling Space and Time with Diffusion Models](https://arxiv.org/pdf/2407.07860)

​	[Tailor3D: Customized 3D Assets Editing and Generation with Dual-Side Images](https://arxiv.org/pdf/2407.06191) 图

​	[Streetscapes: Large-scale Consistent Street View Generation Using Autoregressive Video Diffusion](https://arxiv.org/pdf/2407.13759)

​	

​	4D:

​	[Animate3D: Animating Any 3D Model with Multi-view Video Diffusion](https://arxiv.org/pdf/2407.11398)

​	[SV4D: Dynamic 3D Content Generation with Multi-Frame and Multi-View Consistency](https://arxiv.org/pdf/2407.17470)

​	Flow:

​	[Consistency Flow Matching: Defining Straight Flows with Velocity Consistency](https://arxiv.org/abs/2407.02398)



​	Other:

​	[Mixture of In-Context Experts Enhance LLMs' Long Context Awareness](https://arxiv.org/abs/2406.19598)

​	[Efficient Expert Pruning for Sparse Mixture-of-Experts Language Models: Enhancing Performance and Reducing Inference Costs](https://arxiv.org/abs/2407.00945)



ECCV

​	[Diffusion Soup: Model Merging for Text-to-Image Diffusion Models](https://arxiv.org/abs/2406.08431)

​	[Getting it Right: Improving Spatial Consistency in Text-to-Image Models](https://arxiv.org/abs/2404.01197)

​	[LGM: Large Multi-View Gaussian Model for High-Resolution 3D Content Creation](https://arxiv.org/abs/2402.05054)

​	[**Scaling Up Personalized Image Aesthetic Assessment via Task Vector Customization**](https://arxiv.org/pdf/2407.07176)

​	[Large-scale Reinforcement Learning for Diffusion Models](https://arxiv.org/pdf/2401.12244)

​	[Connecting Consistency Distillation to Score Distillation for Text-to-3D Generation](https://arxiv.org/abs/2407.13584)

​	

CVPR:

​	[InstructRL4Pix: Training Diffusion for Image Editing by Reinforcement Learning](https://arxiv.org/abs/2406.09973)

​	[RLHF-V: Towards Trustworthy MLLMs via Behavior Alignment from Fine-grained Correctional Human Feedback]

​	[Learning Multi-dimensional Human Preference for Text-to-Image Generation](https://arxiv.org/abs/2405.14705)

​	[Rich Human Feedback for Text-to-Image Generation](https://arxiv.org/pdf/2312.10240)



ICLR 24:

​	[Image Conductor: Precision Control for Interactive Video Synthesis](https://arxiv.org/abs/2406.15339)

​	[Contrastive Preference Learning: Learning from Human Feedback without RL](https://arxiv.org/abs/2310.13639)

​	[Compositional preference models for aligning LMs](https://arxiv.org/abs/2310.13011)

​	**[Confidence-aware Reward Optimization for Fine-tuning Text-to-Image Models](https://arxiv.org/abs/2404.01863)** reward model ensemble

​	[Reward Model Ensembles Help Mitigate Overoptimization](https://arxiv.org/abs/2310.02743)

​	[Distributional Preference Learning: Understanding and Accounting for Hidden Context in RLHF](https://arxiv.org/abs/2312.08358)

​	Multi-Task Reinforcement Learning with Mixture of Orthogonal Experts

​	[Mixture of LoRA Experts](https://arxiv.org/abs/2404.13628)



ICLR 25:

​	[HouseCrafter: Lifting Floorplans to 3D Scenes with 2D Diffusion Model](https://arxiv.org/abs/2406.20077)

​	[Solving Token Gradient Conflict in Mixture-of-Experts for Large Vision-Language Model](https://arxiv.org/abs/2406.19905)

​	[StyleShot: A Snapshot on Any Style](https://arxiv.org/abs/2407.01414)



CVPR 25

​	[InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output](https://arxiv.org/abs/2407.03320)

​	[Still-Moving: Customized Video Generation without Customized Video Data](https://arxiv.org/abs/2407.08674)

​	[MARS: Mixture of Auto-Regressive Models for Fine-grained Text-to-image Synthesis](https://arxiv.org/pdf/2407.07614)

​	[Artist: Aesthetically Controllable Text-Driven Stylization without Training ](https://arxiv.org/pdf/2407.15842) content and style



待看:

[Video Diffusion Models are Training-free Motion Interpreter and Controller](https://arxiv.org/abs/2405.14864)

[Neuroexplicit Diffusion Models for Inpainting of Optical Flow Fields](https://arxiv.org/abs/2405.14599)

[Class-Conditional self-reward mechanism for improved Text-to-Image models](https://arxiv.org/abs/2405.13473)

[Directly Denoising Diffusion Model](https://arxiv.org/abs/2405.13540)

[Direct Preference Optimization With Unobserved Preference Heterogeneity](https://arxiv.org/abs/2405.15065)

[FreeCustom: Tuning-Free Customized Image Generation for Multi-Concept Composition](https://arxiv.org/abs/2405.13870)

[Geometry-Aware Score Distillation via 3D Consistent Noising and Gradient Consistency Modeling](https://arxiv.org/abs/2406.16695)
