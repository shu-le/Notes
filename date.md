[3D-VLA: A 3D Vision-Language-Action Generative World Model](https://arxiv.org/abs/2403.09631)

Long-CLIP: Unlocking the Long-Text Capability of CLIP

[What the DAAM: Interpreting Stable Diffusion Using Cross Attention](https://arxiv.org/abs/2210.04885) 解释sd



ICML24: 

[Dense Reward for Free in Reinforcement Learning from Human Feedback](https://arxiv.org/abs/2402.00782)

[Generative Active Learning for Long-tailed Instance Segmentation](https://arxiv.org/abs/2406.02435) 

Visual-Language Models as Fuzzy Rewards for Reinforcement Learning



video:

[Momentor: Advancing Video Large Language Model with Fine-Grained Temporal Reasoning](https://arxiv.org/abs/2402.11435)



NeurIPS

​	RLHF:

​	[Information Theoretic Text-to-Image Alignment](https://arxiv.org/abs/2405.20759)

​	Boost Your Own Human Image Generation Model via Direct Preference Optimization with AI Feedback

​	[Scaling Laws for Reward Model Overoptimization in Direct Alignment Algorithms](https://arxiv.org/abs/2406.02900)

​	[Step-aware Preference Optimization: Aligning Preference with Denoising Performance at Each Step](https://arxiv.org/abs/2406.04314)

​	[Tuning-Free Alignment of Diffusion Models with Direct Noise Optimization](https://arxiv.org/abs/2405.18881)

​	[ReNO: Enhancing One-step Text-to-Image Models through Reward-based Noise Optimization](https://arxiv.org/abs/2406.04312)

​	

​	Video:

​	[Searching Priors Makes Text-to-Video Synthesis Better](https://arxiv.org/abs/2406.03215)

​	[ShareGPT4Video: Improving Video Understanding and Generation with Better Captions](https://arxiv.org/abs/2406.04325)

​	[VIDEOPHY: Evaluating Physical Commonsense for Video Generation](https://arxiv.org/abs/2406.03520)



​	Image: 

​	[Text-to-Image Rectified Flow as Plug-and-Play Priors](https://arxiv.org/abs/2406.03293)

​	[Adapter-X: A Novel General Parameter-Efficient Fine-Tuning Framework for Vision](https://arxiv.org/abs/2406.03051) (Mixture of Adapters)

​	[Understanding the Impact of Negative Prompts: When and How Do They Take Effect?](https://arxiv.org/abs/2406.02965)



​	Evaluate:

​	[A-Bench: Are LMMs Masters at Evaluating AI-generated Images?](https://arxiv.org/abs/2406.03070) Benchmark



​	Gaussian:

​	[Physics3D: Learning Physical Properties of 3D Gaussians via Video Diffusion](https://arxiv.org/abs/2406.04338)

​	[Flash3D: Feed-Forward Generalisable 3D Scene Reconstruction from a Single Image](https://arxiv.org/abs/2406.04343)

​	

待看:

[Video Diffusion Models are Training-free Motion Interpreter and Controller](https://arxiv.org/abs/2405.14864)

[Learning Multi-dimensional Human Preference for Text-to-Image Generation](https://arxiv.org/abs/2405.14705)

[Neuroexplicit Diffusion Models for Inpainting of Optical Flow Fields](https://arxiv.org/abs/2405.14599)

[Class-Conditional self-reward mechanism for improved Text-to-Image models](https://arxiv.org/abs/2405.13473)

[Directly Denoising Diffusion Model](https://arxiv.org/abs/2405.13540)

[Direct Preference Optimization With Unobserved Preference Heterogeneity](https://arxiv.org/abs/2405.15065)

[FreeCustom: Tuning-Free Customized Image Generation for Multi-Concept Composition](https://arxiv.org/abs/2405.13870)

